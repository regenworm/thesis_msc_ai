{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "from n2v import N2VModel\n",
    "from s2v import S2VModel\n",
    "\n",
    "# utility\n",
    "import numpy as np\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from util import data_util as du\n",
    "from util import vis\n",
    "from util import parameters\n",
    "import main\n",
    "\n",
    "# arguments\n",
    "params_run = parameters.get_parameters(notebook=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.run(params_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select run\n",
    "\n",
    "Select run to visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class RunData:\n",
    "    def __init__(self, selected_run):\n",
    "        self.data_path = os.path.join('results', selected_run, 'data')\n",
    "        self.model_output = os.path.join('results', selected_run, 'model_output')\n",
    "        self.plots_path = os.path.join('results', selected_run, 'plots')\n",
    "\n",
    "        # load all data\n",
    "        self.params = parameters.Parameters(du.read_params(os.path.join(self.data_path, 'params_run.bin')))\n",
    "        self.bootstrap_preds_all = du.read_pickle(os.path.join(self.data_path, 'bootstrap_preds_all.bin'))\n",
    "        self.bootstrap_preds_missing = du.read_pickle(os.path.join(self.data_path, 'bootstrap_preds_missing.bin'))\n",
    "        self.bootstrap_preds_spurious = du.read_pickle(os.path.join(self.data_path, 'bootstrap_preds_spurious.bin'))\n",
    "        self.fit_negative_samples = du.read_pickle(os.path.join(self.data_path, 'fit_negative_samples.bin'))\n",
    "        self.missing = du.read_pickle(os.path.join(self.data_path, 'missing.bin'))\n",
    "        self.score_negative_samples = du.read_pickle(os.path.join(self.data_path, 'score_negative_samples.bin'))\n",
    "        self.spurious = du.read_pickle(os.path.join(self.data_path, 'spurious.bin'))\n",
    "        self.train_data = du.load_edge_list(os.path.join(self.data_path, 'train_data.edgelist'), self.params.directed)\n",
    "\n",
    "        # load model\n",
    "        self.model = du.read_pickle(os.path.join(self.model_output, 'model.bin'))\n",
    "\n",
    "available_runs = sorted(os.listdir('results/'))\n",
    "for idx,available in enumerate(available_runs):\n",
    "    metadata = du.read_params(os.path.join('results', available, 'data', 'params_run.bin'))\n",
    "    print(f'{available}:', metadata)\n",
    "# print(available_runs)\n",
    "selected_run = available_runs[-1]\n",
    "rd = RunData(selected_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "Show true data and noisy data for current run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import vis\n",
    "# show data\n",
    "data = du.load_edge_list(rd.params.input_data, rd.params.directed)\n",
    "v = vis.vis_graph(data)\n",
    "plt.show(v)\n",
    "\n",
    "v = vis.vis_graph(rd.train_data)\n",
    "plt.show(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Embeddings\n",
    "As we can see in the visualisations below, embeddings are defined for all possible edges, not just edges that exist in the graph. However, directionality is discarded after embedding. Due to the nature of the implemented edge embeddings, an edge from node 1 to node 2 will output the same edge embedding as an edge from node 2 to node 1. For example, the Hadamard embedding will multiply the node embeddings of node 1 and node 2 together. More info at this link: https://github.com/eliorc/node2vec/issues/36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Nodes')\n",
    "fig2dnodes = vis.vis_embeddings(rd.model.nodes.vectors)\n",
    "plt.show()\n",
    "\n",
    "print('Edges')\n",
    "edge_labels = du.construct_embedding_labels(data, rd.model.ee_kv)\n",
    "embeddings2dedges = vis.vis_edge_embeddings(data, rd.model.ee_kv.vectors, edge_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plots\n",
    "Classify points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# missing\n",
    "# set constants\n",
    "num_runs = len(rd.bootstrap_preds_missing)\n",
    "num_nodes = len(rd.bootstrap_preds_missing[0])\n",
    "\n",
    "# unpack values\n",
    "all_runs_missing_preds, missing_edge_names, _ = du.unpack_values(rd.bootstrap_preds_missing)\n",
    "all_runs_missing_preds = all_runs_missing_preds[:, :, 1]\n",
    "\n",
    "all_runs_negative_fit_labels, all_runs_negative_fit = du.unpack_neg_samples(rd.score_negative_samples)\n",
    "\n",
    "for edge in missing_edge_names:\n",
    "    for neg_run in all_runs_negative_fit_labels:\n",
    "        for label_used in neg_run:\n",
    "            if edge == label_used:\n",
    "                print(f'edge {edge} sampled for fit')\n",
    "\n",
    "# sort columns\n",
    "all_runs_missing_preds = pd.DataFrame(data=all_runs_missing_preds, columns=missing_edge_names)\n",
    "totals = all_runs_missing_preds.sum(axis=0)\n",
    "all_runs_missing_preds = all_runs_missing_preds.append(totals, ignore_index=True).sort_values(num_runs, axis=1).drop(index=num_runs)\n",
    "\n",
    "# plot heatmap\n",
    "fig = vis.plot_heatmap(all_runs_missing_preds, fname=f'{rd.params.model_type}_missing.png', dirname=rd.plots_path, xticklabels=missing_edge_names, figsize=(14,7))\n",
    "plt.title('Missing')\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spurious\n",
    "# set constants\n",
    "num_runs = len(rd.bootstrap_preds_spurious)\n",
    "num_nodes = len(rd.bootstrap_preds_spurious[0])\n",
    "\n",
    "# unpack values\n",
    "all_runs_spurious_preds, spurious_edge_names, _ = du.unpack_values(rd.bootstrap_preds_spurious)\n",
    "all_runs_spurious_preds = all_runs_spurious_preds[:, :, 0]\n",
    "\n",
    "# sort columns\n",
    "all_runs_spurious_preds = pd.DataFrame(data=all_runs_spurious_preds, columns=spurious_edge_names)\n",
    "totals = all_runs_spurious_preds.sum(axis=0)\n",
    "all_runs_spurious_preds = all_runs_spurious_preds.append(totals, ignore_index=True).sort_values(num_runs, axis=1).drop(index=num_runs)\n",
    "\n",
    "# plot heatmap\n",
    "fig = vis.plot_heatmap(all_runs_spurious_preds, fname=f'{rd.params.model_type}_spurious.png', dirname=rd.plots_path, xticklabels=spurious_edge_names, figsize=(14,7))\n",
    "plt.title('Spurious')\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full\n",
    "# set constants\n",
    "num_runs = len(rd.bootstrap_preds_all)\n",
    "num_nodes = len(rd.bootstrap_preds_all[0])\n",
    "\n",
    "# unpack values\n",
    "all_runs_full_preds, full_edge_names, full_labels = du.unpack_values(rd.bootstrap_preds_all)\n",
    "\n",
    "# filter predictions by label\n",
    "all_runs_full_preds = du.filter_preds_by_label(all_runs_full_preds, full_labels)\n",
    "\n",
    "# sort columns\n",
    "all_runs_full_preds = pd.DataFrame(data=all_runs_full_preds, columns=full_edge_names)\n",
    "totals = all_runs_full_preds.sum(axis=0)\n",
    "all_runs_full_preds = all_runs_full_preds.append(totals, ignore_index=True).sort_values(num_runs, axis=1).drop(index=num_runs)\n",
    "\n",
    "\n",
    "# plot heatmap\n",
    "fig = vis.plot_heatmap(all_runs_full_preds.to_numpy(), fname=f'{rd.params.model_type}_full.png', dirname=rd.plots_path, figsize=(14,7))\n",
    "plt.title('Positive')\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "thresh = 0.5\n",
    "# noisy samples\n",
    "print(\"NOISY SAMPLES\")\n",
    "\n",
    "# MISSING\n",
    "print(\"MISSING\")\n",
    "num_runs = len(rd.bootstrap_preds_missing)\n",
    "num_nodes = len(rd.bootstrap_preds_missing[0])\n",
    "all_runs_missing_preds, missing_edge_names, _ = du.unpack_values(rd.bootstrap_preds_missing)\n",
    "# probablistic\n",
    "correct = np.sum(all_runs_missing_preds[:, :, 1])\n",
    "total = num_runs * num_nodes\n",
    "ratio = correct / float(total)\n",
    "# thresholded\n",
    "false_negative = np.sum(all_runs_missing_preds[:, :, 1] > thresh) \n",
    "true_positive = total - true_positive\n",
    "print('correct: ', correct, ', total mass:', total, ', ratio: ', ratio)\n",
    "\n",
    "# SPURIOUS\n",
    "print(\"SPURIOUS\")\n",
    "num_runs = len(rd.bootstrap_preds_spurious)\n",
    "num_nodes = len(rd.bootstrap_preds_spurious[0])\n",
    "all_runs_spurious_preds, spurious_edge_names, _ = du.unpack_values(rd.bootstrap_preds_spurious)\n",
    "# probablistic\n",
    "correct = np.sum(all_runs_spurious_preds[:, :, 0])\n",
    "total = num_runs * num_nodes\n",
    "ratio = correct / float(total)\n",
    "# thresholded\n",
    "false_positive = np.sum(all_runs_spurious_preds[:, :, 0] > thresh) \n",
    "true_negative = total - true_negative\n",
    "print('correct: ', correct, ', total mass:', total, ', ratio: ', ratio)\n",
    "\n",
    "# plot cf matrix\n",
    "print('tp', true_positive, 'tn', true_negative, 'fp', false_positive, 'fn', false_negative)\n",
    "ax = sns.heatmap([[true_negative, false_negative],[false_negative, true_positive]])\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_xlabel('True')\n",
    "plt.show(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL\n",
    "print(\"FULL\")\n",
    "num_runs = len(rd.bootstrap_preds_all)\n",
    "num_nodes = len(rd.bootstrap_preds_all[0])\n",
    "\n",
    "# unpack values\n",
    "all_runs_full_preds, full_edge_names, full_labels = du.unpack_values(rd.bootstrap_preds_all)\n",
    "\n",
    "# filter predictions by label\n",
    "filtered = du.filter_preds_by_label(all_runs_full_preds, full_labels)\n",
    "\n",
    "# probablistic\n",
    "correct = np.sum(filtered)\n",
    "total = num_runs * num_nodes\n",
    "ratio = correct / float(total)\n",
    "\n",
    "# get positive/negative indices\n",
    "positive_indices = np.where(np.array(full_labels).astype(int) == 1)\n",
    "negative_indices = np.where(np.array(full_labels).astype(int) == 0)\n",
    "\n",
    "# get number of tp/tn/fp/fn\n",
    "print('totals', len(filtered[positive_indices]), len(filtered[negative_indices]))\n",
    "true_positive = np.sum((filtered[positive_indices] > thresh))\n",
    "true_negative = np.sum((filtered[negative_indices] > thresh))\n",
    "false_negative = len(filtered[positive_indices]) - true_positive\n",
    "false_positive = len(filtered[negative_indices]) - true_negative\n",
    "print('correct: ', correct, ', total mass:', total, ', ratio: ', ratio)\n",
    "\n",
    "# plot cf matrix\n",
    "ax = sns.heatmap([[true_negative, false_negative],[false_negative, true_positive]], annot=True)\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_xlabel('True')\n",
    "plt.show(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive = 0\n",
    "true_negative = 0\n",
    "false_negative = 0\n",
    "false_positive = 0\n",
    "for edge_idx, labels in zip(range(len(full_edge_names)),full_labels[0]):\n",
    "    e1 = full_edge_names[edge_idx]\n",
    "    similar = (rd.model.nodes.similarity(e1[0],e1[1]) > thresh).astype(int)\n",
    "    if labels == 1.0:\n",
    "        if similar == 1:\n",
    "            true_positive += 1\n",
    "        elif similar == 0:\n",
    "            false_negative += 1\n",
    "    elif labels == 0.0:\n",
    "        if similar == 1:\n",
    "            false_positive += 1\n",
    "        elif similar == 0:\n",
    "            true_negative += 1\n",
    "# print(du.tuple2edge_str(full_edge_names))\n",
    "\n",
    "# plot cf matrix\n",
    "ax = sns.heatmap([[true_negative, false_negative],[false_negative, true_positive]], annot=True)\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_xlabel('True')\n",
    "plt.show(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rl1] *",
   "language": "python",
   "name": "conda-env-rl1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

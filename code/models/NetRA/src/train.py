# for parsing input command
import argparse
import os
import time
import math
import numpy as np
import random

# for logging
import json

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.autograd import Variable

# import utils for data preparation and algorithmic models
from .utils import to_gpu, Corpus, batchify, generate_walks
from .models import Seq2Seq, MLP_D, MLP_G

# import visualization module
from .viz_karate import viz, read_embedding

EMBED_SEGMENT = 4000

# import networkx package for graph data input parse, need to install networkx by: pip install networkx
import networkx as nx

# import scipy package for geting laplacian of graph, need to install networkx by: pip install scipy
from scipy.sparse import csgraph

def parse_args_netra():

    """Parameters to parse
            Path Arguments: The input and output directory
            Data Processing Arguments: data preprocessing for generating ``walks'' from the graph
            Model Arguments: parameters for the model
            Training Arguments, Evaluation Arguments, and others like 
    """
    parser = argparse.ArgumentParser(description='NetRA')
    # Path Arguments
    parser.add_argument('--data_path', type=str, default='../data/karate.adjlist',
                        help='location of the data corpus')                        # location of the graph with linked list format
    parser.add_argument('--outf', type=str, default='example',
                        help='output directory name')                              # location of output embeddings in different epochs

    # Data Processing Arguments
    parser.add_argument('--maxlen', type=int, default=100,
                        help='maximum sentence length')                            # the parameter is for random walk to generating walks,
                                                                                # this is the upbound of the walk length, in the code we generate walks with the same length


    # Model Arguments
    ################### important hyper-parameters ################################
    parser.add_argument('--nhidden', type=int, default=2,
                        help='number of hidden units per layer')                   # dimension of embedding vectors, since we want to visualize to 2-dimensional
    parser.add_argument('--emsize', type=int, default=30,
                        help='size of word embeddings')                            # large graph 100-300, this is the size of input after original one hot embedding's mapping


    ################### typically below are set to default ones ###################
    parser.add_argument('--nlayers', type=int, default=1,
                        help='number of layers')                                   # number of stacked LSTM for autoencoding
    parser.add_argument('--noise_radius', type=float, default=0.2,
                        help='stdev of noise for autoencoder (regularizer)')       # stard deviation of noise for autoencoder
    parser.add_argument('--noise_anneal', type=float, default=0.995,
                        help='anneal noise_radius exponentially by this'
                            'every 100 iterations')                               # decay rate for exponentially decaying noise on autoencoder
    parser.add_argument('--hidden_init', action='store_true',
                        help="initialize decoder hidden state with encoder's")
    parser.add_argument('--arch_g', type=str, default='300-300',
                        help='generator architecture (MLP)')                       # specify the MLP structure of generator in GAN;
                                                                                # for example, 300-300 means two layers, each layer includes 300 nodes
    parser.add_argument('--arch_d', type=str, default='300-300',
                        help='critic/discriminator architecture (MLP)')            # specify the MLP structure of discriminator in GAN;
                                                                                # for example, 300-300 means two layers, each layer includes 300 nodes
    parser.add_argument('--z_size', type=int, default=100,
                        help='dimension of random noise z to feed into generator') # random noise to be feed into the generator
    parser.add_argument('--temp', type=float, default=1,
                        help='softmax temperature (lower --> more discrete)')      # specify the temperature of softmax, \tau
    parser.add_argument('--enc_grad_norm', type=bool, default=True,
                        help='norm code gradient from critic->encoder')
    parser.add_argument('--gan_toenc', type=float, default=-0.01,
                        help='weight factor passing gradient from gan to encoder') # weight factor passing from gradient of GAN to encoder, thi is used by grad_hook
    parser.add_argument('--dropout', type=float, default=0.0,
                        help='dropout applied to layers (0 = no dropout)')         # dropout to prevent overfitting, by default, there is no dropout


    # Training Arguments
    ################### important hyper-parameters ################################
    parser.add_argument('--epochs', type=int, default=50,
                        help='maximum number of epochs')                           # epochs for training, usually small graph 50, large graph 100
    parser.add_argument('--walk_length', type=int, default=20,
                        help='length of walk sampled from the graph')              # the length of walk sampled rooted from each node
    parser.add_argument('--numWalks_per_node', type=int, default=30,
                        help='number of walks sampled for each node')              # number of walks sampled for each node
    parser.add_argument('--batch_size', type=int, default=64, metavar='N',
                        help='batch size')                                         # batch size for training
    parser.add_argument('--niters_ae', type=int, default=1,
                        help='number of autoencoder iterations in training')       # in each epoch, number of iterations for training autoencoder
    parser.add_argument('--niters_gan_d', type=int, default=5,
                        help='number of discriminator iterations in training')     # in each epoch, number of iterations for training discriminator
    parser.add_argument('--niters_gan_g', type=int, default=1,
                        help='number of generator iterations in training')         # in each epoch, number of iterations for training generator

    parser.add_argument('--niters_gan_schedule', type=str, default='2-4-6-10-20-30-40',
                        help='epoch counts to increase number of GAN training '
                            ' iterations (increment by 1 each time)')             # in different epochs, dynamically increase the GAN iterations,
                                                                                # for example, 2-4-6 means, 2 epochs then increase one, 4 epochs then increase again

    ################### typically below are set to default ones ###################
    parser.add_argument('--min_epochs', type=int, default=6,
                        help="minimum number of epochs to train for")              # minimum nuber of epochs for training
    parser.add_argument('--no_earlystopping', action='store_true',
                        help="won't use KenLM for early stopping")                 # if conduct early stopping
    parser.add_argument('--lr_ae', type=float, default=1,
                        help='autoencoder learning rate')                          # learning rate for AE, because it is using SDG, by default it is 1
    parser.add_argument('--lr_gan_g', type=float, default=5e-05,
                        help='generator learning rate')                            # learning rate for generator, because it is using ADM, by default it is a smaller one
    parser.add_argument('--lr_gan_d', type=float, default=1e-05,
                        help='critic/discriminator learning rate')                 # learning rate for discriminator, because it is using ADM, by default it is a smaller one
    parser.add_argument('--beta1', type=float, default=0.9,
                        help='beta1 for adam. default=0.9')                        # beta for adam
    parser.add_argument('--clip', type=float, default=1,
                        help='gradient clipping, max norm')                        # gradient clipping
    parser.add_argument('--gan_clamp', type=float, default=0.01,
                        help='WGAN clamp')                                         # WGAN clamp

    # Evaluation Arguments
    parser.add_argument('--sample', action='store_true',
                        help='sample when decoding for generation')
    parser.add_argument('--log_interval', type=int, default=200,
                        help='interval to log autoencoder training results')

    # Other
    parser.add_argument('--seed', type=int, default=1111,
                        help='random seed')                                        # random seeds for parameter initialization
    parser.add_argument('--cuda', action='store_true',
                        help='use CUDA')                                           # use CUDA for training
    args, _ = parser.parse_known_args()
    return args
    # args = parser.parse_args()
    # print(vars(args))



def save_model(output_path, autoencoder, gan_gen, gan_disc):
    print("Saving models")
    with open(os.path.join(output_path, 'autoencoder_model.pt'), 'wb') as f:
        torch.save(autoencoder.state_dict(), f)
    with open(os.path.join(output_path, 'gan_gen_model.pt'), 'wb') as f:
        torch.save(gan_gen.state_dict(), f)
    with open(os.path.join(output_path, 'gan_disc_model.pt'), 'wb') as f:
        torch.save(gan_disc.state_dict(), f)


def train_netra(A_nx, seed, outputdir, embed_dim):
    args = parse_args_netra()
    print(args)
    args.outf = 'model'
    args.emsize = embed_dim
    args.seed = seed
    
    # make output directory if it doesn't already exist
    if not os.path.isdir(outputdir):
        os.makedirs(outputdir)
    if not os.path.isdir(os.path.join(outputdir, args.outf)):
        os.makedirs(os.path.join(outputdir, args.outf))
    if not os.path.isdir(os.path.join(outputdir, 'tmp')):
        os.makedirs(os.path.join(outputdir, 'tmp'))


    # Set the random seed manually for reproducibility.
    random.seed(args.seed)
    np.random.seed(args.seed)
    torch.manual_seed(args.seed)
    if torch.cuda.is_available():
        if not args.cuda:
            print("WARNING: You have a CUDA device, "
                  "so you should probably run with --cuda")
        else:
            torch.cuda.manual_seed(args.seed)


    ###############################################################################
    # Load data
    ###############################################################################

    print(os.getcwd())
    # # A_nx = nx.read_edgelist(args.data_path,nodetype = int, create_using=nx.DiGraph())  # if the graph is with sparse edge format, each line one edge, then use this
    if A_nx is None:
        A_nx = nx.read_adjlist(args.data_path, nodetype=int)                        # use this for reading adjacent list format graph
    A = nx.to_scipy_sparse_matrix(A_nx)                                         # transfer to sparse matrix format
    L = csgraph.laplacian(A, normed=False)                                      # use csgraph package to calculate the laplacian
    L = np.array(L.toarray(), np.float32)
    L = Variable(torch.from_numpy(L))
    L = to_gpu(args.cuda, L)





    # generate walk for each node with given walk_length
    walks = generate_walks(A_nx, args.numWalks_per_node, args.walk_length)
    # save randomly generated walks to file ../tmp/train.txt
    np.savetxt(os.path.join(outputdir, 'tmp', 'train.txt'), walks, delimiter=" ", fmt="%s")
    

    # create corpus
    corpus = Corpus(os.path.join(outputdir, 'tmp'),
                    maxlen=args.maxlen)
    # dumping vocabulary
    with open(os.path.join(outputdir, args.outf, 'vocab.json'), 'w') as f:
        json.dump(corpus.dictionary.word2idx, f)

    # save arguments to args.json and logs.txt
    ntokens = len(corpus.dictionary.word2idx)
    print("Vocabulary Size: {}".format(ntokens))
    args.ntokens = ntokens
    with open(os.path.join(outputdir, args.outf, 'args.json'), 'w') as f:
        json.dump(vars(args), f)
    with open(os.path.join(outputdir, args.outf, "logs.txt"), 'w') as f:
        f.write(str(vars(args)))
        f.write("\n\n")

    # preparing batches for training
    train_data = batchify(corpus.train, args.batch_size, shuffle=True)

    print("Loaded data!")

    ###############################################################################
    # Build the models
    ###############################################################################

    ntokens = len(corpus.dictionary.word2idx)
    autoencoder = Seq2Seq(emsize=args.emsize,
                        nhidden=args.nhidden,
                        ntokens=ntokens,
                        nlayers=args.nlayers,
                        noise_radius=args.noise_radius,
                        hidden_init=args.hidden_init,
                        dropout=args.dropout,
                        gpu=args.cuda)

    gan_gen = MLP_G(ninput=args.z_size, noutput=args.nhidden, layers=args.arch_g)
    gan_disc = MLP_D(ninput=args.nhidden, noutput=1, layers=args.arch_d)

    print(autoencoder)
    print(gan_gen)
    print(gan_disc)


    #### optimizing AE, GAN-generator, GAN-discriminator
    ## SGD, learning rate should be larger, like 1, Adam's learning rate should be smaller, like 0.001
    optimizer_ae = optim.SGD(autoencoder.parameters(), lr=args.lr_ae)
    optimizer_gan_g = optim.Adam(gan_gen.parameters(),
                                lr=args.lr_gan_g,
                                betas=(args.beta1, 0.999))
    optimizer_gan_d = optim.Adam(gan_disc.parameters(),
                                lr=args.lr_gan_d,
                                betas=(args.beta1, 0.999))
    #### crossEntropy loss for discriminator
    criterion_ce = nn.CrossEntropyLoss()

    if args.cuda:
        autoencoder = autoencoder.cuda()
        gan_gen = gan_gen.cuda()
        gan_disc = gan_disc.cuda()
        criterion_ce = criterion_ce.cuda()


    ###############################################################################
    # Training code
    ###############################################################################



    def embed_afterLSTM(corpus, emsize):
        """
        Getting embedding codes
        :param corpus: nodes of graph
        :param emsize: number of dimensions of embedded codes
        :return: embedding vectors
        """
        dic = corpus.dictionary.word2idx.values()
        dic = np.sort(list(dic))
        if ntokens <= EMBED_SEGMENT:
            dic = np.vstack((dic,dic))
            dic_to_embed = Variable(torch.from_numpy(dic))
            dic_to_embed = to_gpu(args.cuda, dic_to_embed)
            embeded = autoencoder.embed_after_LSTM(dic_to_embed, [ntokens,ntokens])
            dic_vector = embeded[:ntokens].cpu().data.numpy()
        else:
            dic_i = np.array_split(dic, ntokens/EMBED_SEGMENT)
            dic_1 = dic_i[0]
            n_dic_1 = len(dic_1)
            dic_1 = np.vstack((dic_1,dic_1))
            dic_to_embed = Variable(torch.from_numpy(dic_1))
            dic_to_embed = to_gpu(args.cuda, dic_to_embed)
            embeded = autoencoder.embed_after_LSTM(dic_to_embed, [n_dic_1,n_dic_1])
            dic_vector = embeded[:n_dic_1].cpu().data.numpy()
            for j in range(1, ntokens/EMBED_SEGMENT):
                dic_j = dic_i[j]
                n_dic_j = len(dic_j)
                dic_j = np.vstack((dic_j,dic_j))
                dic_to_embed = Variable(torch.from_numpy(dic_j))
                dic_to_embed = to_gpu(args.cuda, dic_to_embed)
                embeded = autoencoder.embed_after_LSTM(dic_to_embed, [n_dic_j,n_dic_j])
                dic_vector_j = embeded[:n_dic_j].cpu().data.numpy()
                dic_vector = np.vstack((dic_vector, dic_vector_j))
            dic = np.vstack((dic,dic))
                
        dic_tosave = np.insert(dic_vector, 0, dic[0], axis=1)

        np.savetxt(os.path.join(outputdir, args.outf, 'embed_afterLSTM_{}.txt'.format(epoch)), dic_tosave,
                fmt=' '.join(['%i'] + ['%1.6f'] * emsize))
        return dic_vector

    def embed_dic_for_loss(corpus, emsize):
        dic = corpus.dictionary.word2idx.values()
        dic = np.sort(list(dic))
        if ntokens <= EMBED_SEGMENT:
            dic = np.vstack((dic,dic))
            dic_to_embed = Variable(torch.from_numpy(dic))
            dic_to_embed = to_gpu(args.cuda, dic_to_embed)
            embeded = autoencoder.embed_after_LSTM(dic_to_embed, [ntokens, ntokens])
            dic_vector = embeded[:ntokens]
        else:
            dic_i = np.array_split(dic, ntokens/EMBED_SEGMENT)
            dic_1 = dic_i[0]
            n_dic_1 = len(dic_1)
            dic_1 = np.vstack((dic_1,dic_1))
            dic_to_embed = Variable(torch.from_numpy(dic_1))
            dic_to_embed = to_gpu(args.cuda, dic_to_embed)
            embeded = autoencoder.embed_after_LSTM(dic_to_embed, [n_dic_1,n_dic_1])
            dic_vector = embeded[:n_dic_1]
            for j in range(1, ntokens/EMBED_SEGMENT):
                dic_j = dic_i[j]
                n_dic_j = len(dic_j)
                dic_j = np.vstack((dic_j,dic_j))
                dic_to_embed = Variable(torch.from_numpy(dic_j))
                dic_to_embed = to_gpu(args.cuda, dic_to_embed)
                embeded = autoencoder.embed_after_LSTM(dic_to_embed, [n_dic_j,n_dic_j])
                dic_vector_j = embeded[:n_dic_j]
                dic_vector = torch.cat((dic_vector, dic_vector_j), 0)
        return dic_vector


    def unique(tensor1d):
        t, idx = np.unique(tensor1d.cpu().data.numpy(), return_index=True)
        return t, idx


    def train_ae(batch, total_loss_ae, start_time, i):
        """
        Training LSTM AE
        :param batch: one batch of data
        :param total_loss_ae: accumulated loss for LSTM AE so far
        :param start_time: for timming
        :param i: current iteration ID
        :return: accumulated total loss of LSTM AE part so far, and start time for timing
        """
        autoencoder.train()
        autoencoder.zero_grad()

        source, target, lengths = batch
        source = to_gpu(args.cuda, Variable(source))
        target = to_gpu(args.cuda, Variable(target))

        # Create sentence length mask over padding
        mask = target.gt(0)
        masked_target = target.masked_select(mask)
        # examples x ntokens
        output_mask = mask.unsqueeze(1).expand(mask.size(0), ntokens)

        # output: batch x seq_len x ntokens
        output = autoencoder(source, lengths, noise=True)

        # output_size: batch_size, maxlen, self.ntokens
        flattened_output = output.view(-1, ntokens)


        emb_py = embed_dic_for_loss(corpus, args.nhidden)
        embT = torch.transpose(emb_py,0,1)
        embT = torch.mm(embT, L)

        adj_loss = torch.trace(torch.mm(embT, emb_py)) / ntokens

        masked_output = \
            flattened_output.masked_select(output_mask).view(-1, ntokens)
        loss = criterion_ce(masked_output/args.temp, masked_target)
        print('loss', loss)

        loss += adj_loss

        loss.backward()

        # `clip_grad_norm` to prevent exploding gradient in RNNs / LSTMs
        # This is the version of Wasserstein GAN, which has gradient clipping
        torch.nn.utils.clip_grad_norm(autoencoder.parameters(), args.clip)
        optimizer_ae.step()

        total_loss_ae += loss.data

        accuracy = None

        ######################## store log periodically ############################
        if i % args.log_interval == 0 and i > 0:
            # accuracy
            probs = F.softmax(masked_output)
            max_vals, max_indices = torch.max(probs, 1)
            accuracy = torch.mean(max_indices.eq(masked_target).float()).data[0]

            cur_loss = total_loss_ae[0] / args.log_interval
            elapsed = time.time() - start_time
            print('| epoch {:3d} | {:5d}/{:5d} batches | ms/batch {:5.2f} | '
                'loss {:5.2f} | ppl {:8.2f} | acc {:8.2f}'
                .format(epoch, i, len(train_data),
                        elapsed * 1000 / args.log_interval,
                        cur_loss, math.exp(cur_loss), accuracy))

            with open(os.path.join(outputdir, args.outf, "logs.txt", 'a')) as f:
                f.write('| epoch {:3d} | {:5d}/{:5d} batches | ms/batch {:5.2f} | '
                        'loss {:5.2f} | ppl {:8.2f} | acc {:8.2f}\n'.
                        format(epoch, i, len(train_data),
                            elapsed * 1000 / args.log_interval,
                            cur_loss, math.exp(cur_loss), accuracy))

            total_loss_ae = 0
            start_time = time.time()

        return total_loss_ae, start_time


    def train_gan_g():
        """
        Training WGAN generator network
        :return: error of generator part
        """
        gan_gen.train()
        gan_gen.zero_grad()

        noise = to_gpu(args.cuda,
                    Variable(torch.ones(args.batch_size, args.z_size)))
        noise.data.normal_(0, 1)

        fake_hidden = gan_gen(noise)
        errG = gan_disc(fake_hidden)

        # loss / backprop
        errG.backward(one.reshape(errG.size()))
        optimizer_gan_g.step()

        return errG


    def grad_hook(grad):
        # Gradient norm: regularize to be same
        # code_grad_gan * code_grad_ae / norm(code_grad_gan)
        if args.enc_grad_norm:
            gan_norm = torch.norm(grad, 2, 1).detach().data.mean()
            normed_grad = grad * autoencoder.grad_norm / gan_norm
        else:
            normed_grad = grad

        # weight factor and sign flip
        normed_grad *= -math.fabs(args.gan_toenc)
        return normed_grad


    def train_gan_d(batch):
        """
        Training WGAN discriminator
        :param batch: training batch data
        :return: discriminator part error
        """
        # clamp parameters to a cube
        # WGAN Weight clipping
        for p in gan_disc.parameters():
            p.data.clamp_(-args.gan_clamp, args.gan_clamp)

        autoencoder.train()
        autoencoder.zero_grad()
        gan_disc.train()
        gan_disc.zero_grad()

        # positive samples ----------------------------
        # generate real codes
        source, target, lengths = batch
        source = to_gpu(args.cuda, Variable(source))
        target = to_gpu(args.cuda, Variable(target))

        # batch_size x nhidden
        real_hidden = autoencoder(source, lengths, noise=False, encode_only=True)
        real_hidden.register_hook(grad_hook)

        # loss / backprop
        errD_real = gan_disc(real_hidden)
        errD_real.backward(one.reshape(errD_real.size()))

        # negative samples ----------------------------
        # generate fake codes
        noise = to_gpu(args.cuda,
                    Variable(torch.ones(args.batch_size, args.z_size)))
        noise.data.normal_(0, 1)

        # loss / backprop
        fake_hidden = gan_gen(noise)
        errD_fake = gan_disc(fake_hidden.detach())
        errD_fake.backward(mone.reshape(errD_fake.size()))

        # `clip_grad_norm` to prvent exploding gradient problem in RNNs / LSTMs
        # This is the version of Wasserstein GAN, which has gradient clipping
        torch.nn.utils.clip_grad_norm(autoencoder.parameters(), args.clip)

        optimizer_gan_d.step()
        optimizer_ae.step()
        errD = -(errD_real - errD_fake)

        return errD, errD_real, errD_fake


    print("Training...")
    with open(os.path.join(outputdir, args.outf, "logs.txt"), 'a') as f:
        f.write('Training...\n')

    # schedule of increasing GAN training loops
    if args.niters_gan_schedule != "":
        gan_schedule = [int(x) for x in args.niters_gan_schedule.split("-")]
    else:
        gan_schedule = []
    niter_gan = 1   # start from 1, and will be dynamically increased

    fixed_noise = to_gpu(args.cuda,
                        Variable(torch.ones(args.batch_size, args.z_size)))
    fixed_noise.data.normal_(0, 1)
    one = to_gpu(args.cuda, torch.FloatTensor([1]))
    mone = one * -1

    for epoch in range(1, args.epochs+1):
        # embed_afterLSTM(corpus, args.nhidden)

        # update gan training schedule
        if epoch in gan_schedule:
            niter_gan += 1
            print("GAN training loop schedule increased to {}".format(niter_gan))
            with open(os.path.join(outputdir, args.outf, "logs.txt"), 'a') as f:
                f.write("GAN training loop schedule increased to {}\n".
                        format(niter_gan))

        total_loss_ae = 0
        epoch_start_time = time.time()
        start_time = time.time()
        niter = 0
        niter_global = 1

        # loop through all batches in training data
        while niter < len(train_data):

            """ 
                Iteratively conduct autoencoder training, then GAN regularization,
                The GAN part includes discriminator and generator iteratively.
            """

            # train autoencoder ----------------------------
            for i in range(args.niters_ae):
                if niter == len(train_data):
                    break  # end of epoch
                total_loss_ae, start_time = \
                    train_ae(train_data[niter], total_loss_ae, start_time, niter)
                niter += 1

            # train gan ----------------------------------
            for k in range(niter_gan):

                # train discriminator/critic
                for i in range(args.niters_gan_d):
                    # feed a seen sample within this epoch; good for early training
                    errD, errD_real, errD_fake = \
                        train_gan_d(train_data[random.randint(0, len(train_data)-1)])

                # train generator
                for i in range(args.niters_gan_g):
                    errG = train_gan_g()



            """
                The codes here are for logging running status, not actually conduct the algorithm logic
            """
            niter_global += 1
            if niter_global % 100 == 0:
                print('[%d/%d][%d/%d] Loss_D: %.8f (Loss_D_real: %.8f '
                    'Loss_D_fake: %.8f) Loss_G: %.8f'
                    % (epoch, args.epochs, niter, len(train_data),
                        errD.data[0], errD_real.data[0],
                        errD_fake.data[0], errG.data[0]))
                with open(os.path.join(outputdir, args.outf, "logs.txt"), 'a') as f:
                    f.write('[%d/%d][%d/%d] Loss_D: %.8f (Loss_D_real: %.8f '
                            'Loss_D_fake: %.8f) Loss_G: %.8f\n'
                            % (epoch, args.epochs, niter, len(train_data),
                            errD.data[0], errD_real.data[0],
                            errD_fake.data[0], errG.data[0]))

                # exponentially decaying noise on autoencoder
                autoencoder.noise_radius = \
                    autoencoder.noise_radius*args.noise_anneal


        # embed_corpus(corpus, args.emsize)
        embed_afterLSTM(corpus, args.nhidden)

        # shuffle between epochs
        train_data = batchify(corpus.train, args.batch_size, shuffle=True)

    ###############################################################################
    # visualization
    ###############################################################################

    # # input membership(label) of each node
    # membership_path = "../data/membership.txt"

    # use last iteration output embeddings as code
    embedding_path = os.path.join(outputdir, args.outf, "embed_afterLSTM_{}.txt")

    # viz_tsne(membership_path, embedding_path)
    # viz(membership_path, embedding_path)
    # save_model(outputdir, autoencoder, gan_gen, gan_disc)

    return read_embedding(embedding_path)



if __name__ == "__main__":
    train_netra(None, 0, './output', 10)
